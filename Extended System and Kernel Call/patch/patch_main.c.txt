1,5c1,3
< /* This file contains the main program of the process manager and some related
<  * procedures.  When MINIX starts up, the kernel runs for a little while,
<  * initializing itself and its tasks, and then it runs PM and VFS.  Both PM
<  * and VFS initialize themselves as far as they can. PM asks the kernel for
<  * all free memory and starts serving requests.
---
> /*
>  * a loop that gets messages requesting work, carries out the work, and sends
>  * replies.
8,9c6,8
<  *   main:	starts PM running
<  *   setreply:	set the reply to be sent to process making an PM system call
---
>  *   main:	main program of the Virtual File System
>  *   reply:	send a reply to a process after the requested work is done
>  *
12,13c11,20
< #include "pm.h"
< #include <minix/keymap.h>
---
> #include "fs.h"
> #include <fcntl.h>
> #include <string.h>
> #include <stdio.h>
> #include <signal.h>
> #include <assert.h>
> #include <stdlib.h>
> #include <sys/ioc_memory.h>
> #include <sys/svrctl.h>
> #include <sys/select.h>
16,17c23,24
< #include <minix/ds.h>
< #include <minix/type.h>
---
> #include <minix/keymap.h>
> #include <minix/const.h>
19,31c26,35
< #include <minix/minlib.h>
< #include <minix/type.h>
< #include <minix/vm.h>
< #include <minix/crtso.h>
< #include <signal.h>
< #include <stdlib.h>
< #include <fcntl.h>
< #include <sys/resource.h>
< #include <sys/utsname.h>
< #include <string.h>
< #include <machine/archtypes.h>
< #include <env.h>
< #include "mproc.h"
---
> #include <minix/safecopies.h>
> #include <minix/debug.h>
> #include <minix/vfsif.h>
> #include "file.h"
> #include "dmap.h"
> #include "fproc.h"
> #include "scratchpad.h"
> #include "vmnt.h"
> #include "vnode.h"
> #include "job.h"
32a37,38
> // Added by Ya Chutiraka 11/22/2016 for project2
> #include "glo.h"
34,37d39
< #include "kernel/const.h"
< #include "kernel/config.h"
< #include "kernel/proc.h"
< 
42,44c44,46
< static void sendreply(void);
< static int get_nice_value(int queue);
< static void handle_vfs_reply(void);
---
> // Added by Ya Chutiraka 11/22/2016 for project2
> struct buffer_vfs buffer_vfs[BUFFER_SIZE];
> const char* getStateName_4(enum State state);
46,47c48,56
< #define click_to_round_k(n) \
< 	((unsigned) ((((unsigned long) (n) << CLICK_SHIFT) + 512) / 1024))
---
> const char* getStateName_4(enum State state) {
>    switch (state) {
> 	  case NEWLY_CREATED: return "NEWLY_CREATED";
> 	  case READY: return "READY";
> 	  case RUNNING: return "RUNNING";
> 	  case BLOCKED: return "BLOCKED";
> 	  case TERMINATED: return "TERMINATED";
>    }
> }
48a58,74
> /* Thread related prototypes */
> static void *do_async_dev_result(void *arg);
> static void *do_control_msgs(void *arg);
> static void *do_dev_event(void *arg);
> static void *do_fs_reply(struct job *job);
> static void *do_work(void *arg);
> static void *do_pm(void *arg);
> static void *do_init_root(void *arg);
> static void handle_work(void *(*func)(void *arg));
> 
> static void get_work(void);
> static void lock_pm(void);
> static void unlock_pm(void);
> static void service_pm(void);
> static void service_pm_postponed(void);
> static int unblock(struct fproc *rfp);
> 
52c78,79
< static int sef_cb_signal_manager(endpoint_t target, int signo);
---
> static mutex_t pm_lock;
> static endpoint_t receive_from;
57c84
< int main()
---
> int main(void)
59,60c86,91
< /* Main routine of the process manager. */
<   int result;
---
> /* This is the main program of the file system.  The main loop consists of
>  * three major activities: getting new work, processing the work, and sending
>  * the reply.  This loop never terminates as long as the file system runs.
>  */
>   int transid;
>   struct job *job;
65,67c96
<   /* This is PM's main loop-  get work and do it, forever and forever. */
<   while (TRUE) {
< 	  int ipc_status;
---
>   printf("Started VFS: %d worker thread(s)\n", NR_WTHREADS);
69,75c98,99
< 	  /* Wait for the next message and extract useful information from it. */
< 	  if (sef_receive_status(ANY, &m_in, &ipc_status) != OK)
< 		  panic("PM sef_receive_status error");
< 	  who_e = m_in.m_source;	/* who sent the message */
< 	  if(pm_isokendpt(who_e, &who_p) != OK)
< 		  panic("PM got message from invalid endpoint: %d", who_e);
< 	  call_nr = m_in.m_type;	/* system call number */
---
>   if (OK != (sys_getkinfo(&kinfo)))
> 	panic("couldn't get kernel kinfo");
77,85c101,107
< 	  /* Process slot of caller. Misuse PM's own process slot if the kernel is
< 	   * calling. This can happen in case of synchronous alarms (CLOCK) or or
< 	   * event like pending kernel signals (SYSTEM).
< 	   */
< 	  mp = &mproc[who_p < 0 ? PM_PROC_NR : who_p];
< 	  if(who_p >= 0 && mp->mp_endpoint != who_e) {
< 		  panic("PM endpoint number out of sync with source: %d",
< 				  			mp->mp_endpoint);
< 	  }
---
>   /* This is the main loop that gets work, processes it, and sends replies. */
>   while (TRUE) {
> 	yield_all();	/* let other threads run */
> 	self = NULL;
> 	job = NULL;
> 	send_work();
> 	get_work();
87,88c109,121
< 	/* Drop delayed calls from exiting processes. */
< 	if (mp->mp_flags & EXITING)
---
> 	transid = TRNS_GET_ID(m_in.m_type);
> 	if (IS_VFS_FS_TRANSID(transid)) {
> 		job = worker_getjob( (thread_t) transid - VFS_TRANSID);
> 		if (job == NULL) {
> 			printf("VFS: spurious message %d from endpoint %d\n",
> 				m_in.m_type, m_in.m_source);
> 			continue;
> 		}
> 		m_in.m_type = TRNS_DEL_ID(m_in.m_type);
> 	}
> 
> 	if (job != NULL) {
> 		do_fs_reply(job);
89a123,161
> 	} else if (who_e == PM_PROC_NR) { /* Calls from PM */
> 		/* Special control messages from PM */
> 		sys_worker_start(do_pm);
> 		continue;
> 	} else if (is_notify(call_nr)) {
> 		/* A task notify()ed us */
> 		if (who_e == DS_PROC_NR)
> 			handle_work(ds_event);
> 		else if (who_e == KERNEL){
> 			mthread_stacktraces();
> 	    }
> 		else if (fp != NULL && (fp->fp_flags & FP_SRV_PROC))
> 			handle_work(do_dev_event);
> 		else
> 			sys_worker_start(do_control_msgs);
> 		continue;
> 	} else if (who_p < 0) { /* i.e., message comes from a task */
> 		if (who_e == KERNEL && m_in.m_type == KERNEL_TO_VFS) { // Added by Ya Chutiraka 11/22/2016 for project2
> 			//printf("\nm1_i2 = %d, KERNEL_TO_VFS = %d", m_in.m1_i2, KERNEL_TO_VFS);
> 			//src_proc = m.m1_i2 = (endpoint_lookup(KERNEL))->p_endpoint
> 		    //src_vir = m_in.m1_p1 = (char *) &(buffer_plog[0])
> 		    //dst_proc = SELF
> 		    //dst_proc = &(buffer_vfs[0])
> 		    //bytes = sizeof(buffer_vfs)
> 		    sys_vircopy(who_e, (vir_bytes) m_in.m1_p1, SELF, (vir_bytes) &(buffer_vfs[0]), sizeof(buffer_vfs));
> 			
> 			for(int i =0; i< BUFFER_SIZE; i++){
> 				printf("PID: %d     from: %s      to: %s     timestamp: %ld\n", buffer_vfs[i].thisPID, getStateName_4(buffer_vfs[i].fromState), getStateName_4(buffer_vfs[i].toState), (long)buffer_vfs[i].timestamp);
> 			}
> 		}
> 		
> 		else {
> 		/* We're going to ignore this message. Tasks should
> 		 * send notify()s only.
> 		 */
> 		 printf("VFS: ignoring message from %d (%d)\n", who_e, call_nr);
> 		 }
> 		 continue;
>     }
91,94c163,187
< 	/* Check for system notifications first. Special cases. */
< 	if (is_ipc_notify(ipc_status)) {
< 		if (who_p == CLOCK) {
< 			expire_timers(m_in.NOTIFY_TIMESTAMP);
---
> 	/* At this point we either have results from an asynchronous device
> 	 * or a new system call. In both cases a new worker thread has to be
> 	 * started and there might not be one available from the pool. This is
> 	 * not a problem (requests/replies are simply queued), except when
> 	 * they're from an FS endpoint, because these can cause a deadlock.
> 	 * handle_work() takes care of the details. */
> 	if (IS_DRV_REPLY(call_nr)) {
> 		/* We've got results for a device request */
> 
> 		struct dmap *dp;
> 
> 		dp = get_dmap(who_e);
> 		if (dp != NULL) {
> 			if (dev_style_asyn(dp->dmap_style)) {
> 				handle_work(do_async_dev_result);
> 
> 			} else {
> 				if (dp->dmap_servicing == NONE) {
> 					printf("Got spurious dev reply from %d",
> 					who_e);
> 				} else {
> 					dev_reply(dp);
> 				}
> 			}
> 			continue;
95a189,197
> 		printf("VFS: ignoring dev reply from unknown driver %d\n",
> 			who_e);
> 	} else {
> 		/* Normal syscall. */
> 		handle_work(do_work);
> 	}
>   }
>   return(OK);				/* shouldn't come here */
> }
97,99c199,225
< 		/* done, send reply and continue */
< 		sendreply();
< 		continue;
---
> /*===========================================================================*
>  *			       handle_work				     *
>  *===========================================================================*/
> static void handle_work(void *(*func)(void *arg))
> {
> /* Handle asynchronous device replies and new system calls. If the originating
>  * endpoint is an FS endpoint, take extra care not to get in deadlock. */
>   struct vmnt *vmp = NULL;
>   endpoint_t proc_e;
> 
>   proc_e = m_in.m_source;
> 
>   if (fp->fp_flags & FP_SRV_PROC) {
> 	vmp = find_vmnt(proc_e);
> 	if (vmp != NULL) {
> 		/* A call back or dev result from an FS
> 		 * endpoint. Set call back flag. Can do only
> 		 * one call back at a time.
> 		 */
> 		if (vmp->m_flags & VMNT_CALLBACK) {
> 			reply(proc_e, EAGAIN);
> 			return;
> 		}
> 		vmp->m_flags |= VMNT_CALLBACK;
> 		if (vmp->m_flags & VMNT_MOUNTING) {
> 			vmp->m_flags |= VMNT_FORCEROOTBSF;
> 		}
102,118c228,232
< 	switch(call_nr)
< 	{
< 	case PM_SETUID_REPLY:
< 	case PM_SETGID_REPLY:
< 	case PM_SETSID_REPLY:
< 	case PM_EXEC_REPLY:
< 	case PM_EXIT_REPLY:
< 	case PM_CORE_REPLY:
< 	case PM_FORK_REPLY:
< 	case PM_SRV_FORK_REPLY:
< 	case PM_UNPAUSE_REPLY:
< 	case PM_REBOOT_REPLY:
< 	case PM_SETGROUPS_REPLY:
< 		if (who_e == VFS_PROC_NR)
< 		{
< 			handle_vfs_reply();
< 			result= SUSPEND;		/* don't reply */
---
> 	if (worker_available() == 0) {
> 		if (!deadlock_resolving) {
> 			deadlock_resolving = 1;
> 			dl_worker_start(func);
> 			return;
120,135d233
< 		else
< 			result= ENOSYS;
< 		break;
< 	case COMMON_GETSYSINFO:
< 		result = do_getsysinfo();
< 		break;
< 	default:
< 		/* Else, if the system call number is valid, perform the
< 		 * call.
< 		 */
< 		if ((unsigned) call_nr >= NCALLS) {
< 			result = ENOSYS;
< 		} else {
< #if ENABLE_SYSCALL_STATS
< 			calls_stats[call_nr]++;
< #endif
137c235,237
< 			result = (*call_vec[call_nr])();
---
> 		if (vmp != NULL) {
> 			/* Already trying to resolve a deadlock, can't
> 			 * handle more, sorry */
138a239,240
> 			reply(proc_e, EAGAIN);
> 			return;
140d241
< 		break;
141a243
>   }
143,145c245,272
< 	/* Send reply. */
< 	if (result != SUSPEND) setreply(who_p, result);
< 	sendreply();
---
>   worker_start(func);
> }
> 
> /*===========================================================================*
>  *			       do_async_dev_result			     *
>  *===========================================================================*/
> static void *do_async_dev_result(void *arg)
> {
>   endpoint_t endpt;
>   struct job my_job;
> 
>   my_job = *((struct job *) arg);
>   fp = my_job.j_fp;
> 
>   /* An asynchronous character driver has results for us */
>   if (job_call_nr == DEV_REVIVE) {
> 	endpt = job_m_in.REP_ENDPT;
> 	if (endpt == VFS_PROC_NR)
> 		endpt = find_suspended_ep(job_m_in.m_source,
> 					  job_m_in.REP_IO_GRANT);
> 
> 	if (endpt == NONE) {
> 		printf("VFS: proc with grant %d from %d not found\n",
> 			job_m_in.REP_IO_GRANT, job_m_in.m_source);
> 	} else if (job_m_in.REP_STATUS == SUSPEND) {
> 		printf("VFS: got SUSPEND on DEV_REVIVE: not reviving proc\n");
> 	} else
> 		revive(endpt, job_m_in.REP_STATUS);
147c274,285
<   return(OK);
---
>   else if (job_call_nr == DEV_OPEN_REPL) open_reply();
>   else if (job_call_nr == DEV_REOPEN_REPL) reopen_reply();
>   else if (job_call_nr == DEV_CLOSE_REPL) close_reply();
>   else if (job_call_nr == DEV_SEL_REPL1)
> 	select_reply1(job_m_in.m_source, job_m_in.DEV_MINOR,
> 		      job_m_in.DEV_SEL_OPS);
>   else if (job_call_nr == DEV_SEL_REPL2)
> 	select_reply2(job_m_in.m_source, job_m_in.DEV_MINOR,
> 		      job_m_in.DEV_SEL_OPS);
> 
>   thread_cleanup(fp);
>   return(NULL);
150a289,507
>  *			       do_control_msgs				     *
>  *===========================================================================*/
> static void *do_control_msgs(void *arg)
> {
>   struct job my_job;
> 
>   my_job = *((struct job *) arg);
>   fp = my_job.j_fp;
> 
>   /* Check for special control messages. */
>   if (job_m_in.m_source == CLOCK) {
> 	/* Alarm timer expired. Used only for select(). Check it. */
> 	expire_timers(job_m_in.NOTIFY_TIMESTAMP);
>   }
> 
>   thread_cleanup(NULL);
>   return(NULL);
> }
> 
> /*===========================================================================*
>  *			       do_dev_event				     *
>  *===========================================================================*/
> static void *do_dev_event(void *arg)
> {
> /* Device notifies us of an event. */
>   struct job my_job;
> 
>   my_job = *((struct job *) arg);
>   fp = my_job.j_fp;
> 
>   dev_status(job_m_in.m_source);
> 
>   thread_cleanup(fp);
>   return(NULL);
> }
> 
> /*===========================================================================*
>  *			       do_fs_reply				     *
>  *===========================================================================*/
> static void *do_fs_reply(struct job *job)
> {
>   struct vmnt *vmp;
>   struct worker_thread *wp;
> 
>   if ((vmp = find_vmnt(who_e)) == NULL)
> 	panic("Couldn't find vmnt for endpoint %d", who_e);
> 
>   wp = worker_get(job->j_fp->fp_wtid);
> 
>   if (wp == NULL) {
> 	printf("VFS: spurious reply from %d\n", who_e);
> 	return(NULL);
>   }
> 
>   if (wp->w_task != who_e) {
> 	printf("VFS: expected %d to reply, not %d\n", wp->w_task, who_e);
> 	return(NULL);
>   }
>   *wp->w_fs_sendrec = m_in;
>   wp->w_task = NONE;
>   vmp->m_comm.c_cur_reqs--; /* We've got our reply, make room for others */
>   worker_signal(wp); /* Continue this thread */
>   return(NULL);
> }
> 
> /*===========================================================================*
>  *				lock_pm					     *
>  *===========================================================================*/
> static void lock_pm(void)
> {
>   struct fproc *org_fp;
>   struct worker_thread *org_self;
> 
>   /* First try to get it right off the bat */
>   if (mutex_trylock(&pm_lock) == 0)
> 	return;
> 
>   org_fp = fp;
>   org_self = self;
> 
>   if (mutex_lock(&pm_lock) != 0)
> 	panic("Could not obtain lock on pm\n");
> 
>   fp = org_fp;
>   self = org_self;
> }
> 
> /*===========================================================================*
>  *				unlock_pm				     *
>  *===========================================================================*/
> static void unlock_pm(void)
> {
>   if (mutex_unlock(&pm_lock) != 0)
> 	panic("Could not release lock on pm");
> }
> 
> /*===========================================================================*
>  *			       do_pm					     *
>  *===========================================================================*/
> static void *do_pm(void *arg __unused)
> {
>   lock_pm();
>   service_pm();
>   unlock_pm();
> 
>   thread_cleanup(NULL);
>   return(NULL);
> }
> 
> /*===========================================================================*
>  *			       do_pending_pipe				     *
>  *===========================================================================*/
> static void *do_pending_pipe(void *arg)
> {
>   int r, op;
>   struct job my_job;
>   struct filp *f;
>   tll_access_t locktype;
> 
>   my_job = *((struct job *) arg);
>   fp = my_job.j_fp;
> 
>   lock_proc(fp, 1 /* force lock */);
> 
>   f = scratch(fp).file.filp;
>   assert(f != NULL);
>   scratch(fp).file.filp = NULL;
> 
>   locktype = (job_call_nr == READ) ? VNODE_READ : VNODE_WRITE;
>   op = (job_call_nr == READ) ? READING : WRITING;
>   lock_filp(f, locktype);
> 
>   r = rw_pipe(op, who_e, f, scratch(fp).io.io_buffer, scratch(fp).io.io_nbytes);
> 
>   if (r != SUSPEND)  /* Do we have results to report? */
> 	reply(fp->fp_endpoint, r);
> 
>   unlock_filp(f);
>   thread_cleanup(fp);
>   unlock_proc(fp);
>   return(NULL);
> }
> 
> /*===========================================================================*
>  *			       do_dummy					     *
>  *===========================================================================*/
> void *do_dummy(void *arg)
> {
>   struct job my_job;
>   int r;
> 
>   my_job = *((struct job *) arg);
>   fp = my_job.j_fp;
> 
>   if ((r = mutex_trylock(&fp->fp_lock)) == 0) {
> 	thread_cleanup(fp);
> 	unlock_proc(fp);
>   } else {
> 	/* Proc is busy, let that worker thread carry out the work */
> 	thread_cleanup(NULL);
>   }
>   return(NULL);
> }
> 
> /*===========================================================================*
>  *			       do_work					     *
>  *===========================================================================*/
> static void *do_work(void *arg)
> {
>   int error;
>   struct job my_job;
> 
>   my_job = *((struct job *) arg);
>   fp = my_job.j_fp;
> 
>   lock_proc(fp, 0); /* This proc is busy */
> 
>   if (job_call_nr == MAPDRIVER) {
> 	error = do_mapdriver();
>   } else if (job_call_nr == COMMON_GETSYSINFO) {
> 	error = do_getsysinfo();
>   } else if (IS_PFS_VFS_RQ(job_call_nr)) {
> 	if (who_e != PFS_PROC_NR) {
> 		printf("VFS: only PFS is allowed to make nested VFS calls\n");
> 		error = ENOSYS;
> 	} else if (job_call_nr <= PFS_BASE ||
> 		   job_call_nr >= PFS_BASE + PFS_NREQS) {
> 		error = ENOSYS;
> 	} else {
> 		job_call_nr -= PFS_BASE;
> 		error = (*pfs_call_vec[job_call_nr])();
> 	}
>   } else {
> 	/* We're dealing with a POSIX system call from a normal
> 	 * process. Call the internal function that does the work.
> 	 */
> 	if (job_call_nr < 0 || job_call_nr >= NCALLS) {
> 		error = ENOSYS;
> 	} else if (fp->fp_pid == PID_FREE) {
> 		/* Process vanished before we were able to handle request.
> 		 * Replying has no use. Just drop it. */
> 		error = SUSPEND;
> 	} else {
> #if ENABLE_SYSCALL_STATS
> 		calls_stats[job_call_nr]++;
> #endif
> 		error = (*call_vec[job_call_nr])();
> 	}
>   }
> 
>   /* Copy the results back to the user and send reply. */
>   if (error != SUSPEND) reply(fp->fp_endpoint, error);
> 
>   thread_cleanup(fp);
>   unlock_proc(fp);
>   return(NULL);
> }
> 
> /*===========================================================================*
161,163d517
<   /* Register signal callbacks. */
<   sef_setcb_signal_manager(sef_cb_signal_manager);
< 
169c523
<  *		            sef_cb_init_fresh                                *
---
>  *				sef_cb_init_fresh			     *
171c525
< static int sef_cb_init_fresh(int UNUSED(type), sef_init_info_t *UNUSED(info))
---
> static int sef_cb_init_fresh(int UNUSED(type), sef_init_info_t *info)
173,194c527,529
< /* Initialize the process manager. 
<  * Memory use info is collected from the boot monitor, the kernel, and
<  * all processes compiled into the system image. Initially this information
<  * is put into an array mem_chunks. Elements of mem_chunks are struct memory,
<  * and hold base, size pairs in units of clicks. This array is small, there
<  * should be no more than 8 chunks. After the array of chunks has been built
<  * the contents are used to initialize the hole list. Space for the hole list
<  * is reserved as an array with twice as many elements as the maximum number
<  * of processes allowed. It is managed as a linked list, and elements of the
<  * array are struct hole, which, in addition to storage for a base and size in 
<  * click units also contain space for a link, a pointer to another element.
< */
<   int s;
<   static struct boot_image image[NR_BOOT_PROCS];
<   register struct boot_image *ip;
<   static char core_sigs[] = { SIGQUIT, SIGILL, SIGTRAP, SIGABRT,
< 				SIGEMT, SIGFPE, SIGBUS, SIGSEGV };
<   static char ign_sigs[] = { SIGCHLD, SIGWINCH, SIGCONT };
<   static char noign_sigs[] = { SIGILL, SIGTRAP, SIGEMT, SIGFPE, 
< 				SIGBUS, SIGSEGV };
<   register struct mproc *rmp;
<   register char *sig_ptr;
---
> /* Initialize the virtual file server. */
>   int s, i;
>   struct fproc *rfp;
195a531
>   struct rprocpub rprocpub[NR_BOOT_PROCS];
197,200c533,541
<   /* Initialize process table, including timers. */
<   for (rmp=&mproc[0]; rmp<&mproc[NR_PROCS]; rmp++) {
< 	init_timer(&rmp->mp_timer);
< 	rmp->mp_magic = MP_MAGIC;
---
>   force_sync = 0;
>   receive_from = ANY;
>   self = NULL;
>   verbose = 0;
> 
>   /* Initialize proc endpoints to NONE */
>   for (rfp = &fproc[0]; rfp < &fproc[NR_PROCS]; rfp++) {
> 	rfp->fp_endpoint = NONE;
> 	rfp->fp_pid = PID_FREE;
203,204c544,547
<   /* Build the set of signals which cause core dumps, and the set of signals
<    * that are by default ignored.
---
>   /* Initialize the process table with help of the process manager messages.
>    * Expect one message for each system process with its slot number and pid.
>    * When no more processes follow, the magic process number NONE is sent.
>    * Then, stop and synchronize with the PM.
206,214c549,551
<   sigemptyset(&core_sset);
<   for (sig_ptr = core_sigs; sig_ptr < core_sigs+sizeof(core_sigs); sig_ptr++)
< 	sigaddset(&core_sset, *sig_ptr);
<   sigemptyset(&ign_sset);
<   for (sig_ptr = ign_sigs; sig_ptr < ign_sigs+sizeof(ign_sigs); sig_ptr++)
< 	sigaddset(&ign_sset, *sig_ptr);
<   sigemptyset(&noign_sset);
<   for (sig_ptr = noign_sigs; sig_ptr < noign_sigs+sizeof(noign_sigs); sig_ptr++)
< 	sigaddset(&noign_sset, *sig_ptr);
---
>   do {
> 	if ((s = sef_receive(PM_PROC_NR, &mess)) != OK)
> 		panic("VFS: couldn't receive from PM: %d", s);
216,223c553,554
<   /* Obtain a copy of the boot monitor parameters and the kernel info struct.  
<    * Parse the list of free memory chunks. This list is what the boot monitor 
<    * reported, but it must be corrected for the kernel and system processes.
<    */
<   if ((s=sys_getmonparams(monitor_params, sizeof(monitor_params))) != OK)
<       panic("get monitor params failed: %d", s);
<   if ((s=sys_getkinfo(&kinfo)) != OK)
<       panic("get kernel info failed: %d", s);
---
> 	if (mess.m_type != PM_INIT)
> 		panic("unexpected message from PM: %d", mess.m_type);
225,233c556
<   /* Initialize PM's process table. Request a copy of the system image table 
<    * that is defined at the kernel level to see which slots to fill in.
<    */
<   if (OK != (s=sys_getimage(image))) 
<   	panic("couldn't get image table: %d", s);
<   procs_in_use = 0;				/* start populating table */
<   for (ip = &image[0]; ip < &image[NR_BOOT_PROCS]; ip++) {
<   	if (ip->proc_nr >= 0) {			/* task have negative nrs */
<   		procs_in_use += 1;		/* found user process */
---
> 	if (NONE == mess.PM_PROC) break;
235,249c558,571
< 		/* Set process details found in the image table. */
< 		rmp = &mproc[ip->proc_nr];	
<   		strlcpy(rmp->mp_name, ip->proc_name, PROC_NAME_LEN); 
<   		(void) sigemptyset(&rmp->mp_ignore);	
<   		(void) sigemptyset(&rmp->mp_sigmask);
<   		(void) sigemptyset(&rmp->mp_catch);
< 		if (ip->proc_nr == INIT_PROC_NR) {	/* user process */
<   			/* INIT is root, we make it father of itself. This is
<   			 * not really OK, INIT should have no father, i.e.
<   			 * a father with pid NO_PID. But PM currently assumes 
<   			 * that mp_parent always points to a valid slot number.
<   			 */
<   			rmp->mp_parent = INIT_PROC_NR;
<   			rmp->mp_procgrp = rmp->mp_pid = INIT_PID;
< 			rmp->mp_flags |= IN_USE; 
---
> 	rfp = &fproc[mess.PM_SLOT];
> 	rfp->fp_flags = FP_NOFLAGS;
> 	rfp->fp_pid = mess.PM_PID;
> 	rfp->fp_endpoint = mess.PM_PROC;
> 	rfp->fp_grant = GRANT_INVALID;
> 	rfp->fp_blocked_on = FP_BLOCKED_ON_NONE;
> 	rfp->fp_realuid = (uid_t) SYS_UID;
> 	rfp->fp_effuid = (uid_t) SYS_UID;
> 	rfp->fp_realgid = (gid_t) SYS_GID;
> 	rfp->fp_effgid = (gid_t) SYS_GID;
> 	rfp->fp_umask = ~0;
>   } while (TRUE);			/* continue until process NONE */
>   mess.m_type = OK;			/* tell PM that we succeeded */
>   s = send(PM_PROC_NR, &mess);		/* send synchronization message */
251,263c573,577
< 			/* Set scheduling info */
< 			rmp->mp_scheduler = KERNEL;
< 			rmp->mp_nice = get_nice_value(USR_Q);
< 		}
< 		else {					/* system process */
<   			if(ip->proc_nr == RS_PROC_NR) {
<   				rmp->mp_parent = INIT_PROC_NR;
<   			}
<   			else {
<   				rmp->mp_parent = RS_PROC_NR;
<   			}
<   			rmp->mp_pid = get_free_pid();
< 			rmp->mp_flags |= IN_USE | PRIV_PROC;
---
>   /* All process table entries have been set. Continue with initialization. */
>   fp = &fproc[_ENDPOINT_P(VFS_PROC_NR)];/* During init all communication with
> 					 * FSes is on behalf of myself */
>   init_dmap();			/* Initialize device table. */
>   system_hz = sys_hz();
265,267c579,587
< 			/* RS schedules this process */
< 			rmp->mp_scheduler = NONE;
< 			rmp->mp_nice = get_nice_value(SRV_Q);
---
>   /* Map all the services in the boot image. */
>   if ((s = sys_safecopyfrom(RS_PROC_NR, info->rproctab_gid, 0,
> 			    (vir_bytes) rprocpub, sizeof(rprocpub))) != OK){
> 	panic("sys_safecopyfrom failed: %d", s);
>   }
>   for (i = 0; i < NR_BOOT_PROCS; i++) {
> 	if (rprocpub[i].in_use) {
> 		if ((s = map_service(&rprocpub[i])) != OK) {
> 			panic("VFS: unable to map service: %d", s);
268a589,590
> 	}
>   }
270,271c592,594
< 		/* Get kernel endpoint identifier. */
< 		rmp->mp_endpoint = ip->endpoint;
---
>   /* Subscribe to block and character driver events. */
>   s = ds_subscribe("drv\\.[bc]..\\..*", DSF_INITIAL | DSF_OVERWRITE);
>   if (s != OK) panic("VFS: can't subscribe to driver events (%d)", s);
273,280c596,598
< 		/* Tell VFS about this system process. */
< 		mess.m_type = PM_INIT;
< 		mess.PM_SLOT = ip->proc_nr;
< 		mess.PM_PID = rmp->mp_pid;
< 		mess.PM_PROC = rmp->mp_endpoint;
<   		if (OK != (s=send(VFS_PROC_NR, &mess)))
< 			panic("can't sync up with VFS: %d", s);
<   	}
---
>   /* Initialize worker threads */
>   for (i = 0; i < NR_WTHREADS; i++)  {
> 	worker_init(&workers[i]);
281a600,601
>   worker_init(&sys_worker); /* exclusive system worker thread */
>   worker_init(&dl_worker); /* exclusive worker thread to resolve deadlocks */
283,286c603,609
<   /* Tell VFS that no more system processes follow and synchronize. */
<   mess.PR_ENDPT = NONE;
<   if (sendrec(VFS_PROC_NR, &mess) != OK || mess.m_type != OK)
< 	panic("can't sync up with VFS");
---
>   /* Initialize global locks */
>   if (mthread_mutex_init(&pm_lock, NULL) != 0)
> 	panic("VFS: couldn't initialize pm lock mutex");
>   if (mthread_mutex_init(&exec_lock, NULL) != 0)
> 	panic("VFS: couldn't initialize exec lock");
>   if (mthread_mutex_init(&bsf_lock, NULL) != 0)
> 	panic("VFS: couldn't initialize block special file lock");
288,293c611,619
< #if defined(__i386__)
<         uts_val.machine[0] = 'i';
<         strcpy(uts_val.machine + 1, itoa(getprocessor()));
< #elif defined(__arm__)
<         strcpy(uts_val.machine, "arm");
< #endif  
---
>   /* Initialize event resources for boot procs and locks for all procs */
>   for (rfp = &fproc[0]; rfp < &fproc[NR_PROCS]; rfp++) {
> 	if (mutex_init(&rfp->fp_lock, NULL) != 0)
> 		panic("unable to initialize fproc lock");
> #if LOCK_DEBUG
> 	rfp->fp_vp_rdlocks = 0;
> 	rfp->fp_vmnt_rdlocks = 0;
> #endif
>   }
295c621,629
<  system_hz = sys_hz();
---
>   init_dmap_locks();		/* init dmap locks */
>   init_vnodes();		/* init vnodes */
>   init_vmnts();			/* init vmnt structures */
>   init_select();		/* init select() structures */
>   init_filps();			/* Init filp structures */
>   mount_pfs();			/* mount Pipe File Server */
>   worker_start(do_init_root);	/* mount initial ramdisk as file system root */
>   yield();			/* force do_init_root to start */
>   self = NULL;
297,299d630
<   /* Initialize user-space scheduling. */
<   sched_init();
< 
304c635
<  *		            sef_cb_signal_manager                            *
---
>  *			       do_init_root				     *
306c637
< static int sef_cb_signal_manager(endpoint_t target, int signo)
---
> static void *do_init_root(void *arg)
308c639,640
< /* Process signal on behalf of the kernel. */
---
>   struct fproc *rfp;
>   struct job my_job;
309a642
>   char *mount_label = "fs_imgrd"; /* FIXME: obtain this from RS */
311,312c644,645
<   r = process_ksig(target, signo);
<   sendreply();
---
>   my_job = *((struct job *) arg);
>   fp = my_job.j_fp;
314c647,667
<   return r;
---
>   lock_proc(fp, 1 /* force lock */); /* This proc is busy */
>   lock_pm();
> 
>   /* Initialize process directories. mount_fs will set them to the correct
>    * values */
>   for (rfp = &fproc[0]; rfp < &fproc[NR_PROCS]; rfp++) {
> 	FD_ZERO(&(rfp->fp_filp_inuse));
> 	rfp->fp_rd = NULL;
> 	rfp->fp_wd = NULL;
>   }
> 
>   receive_from = MFS_PROC_NR;
>   r = mount_fs(DEV_IMGRD, "bootramdisk", "/", MFS_PROC_NR, 0, mount_label);
>   if (r != OK)
> 	panic("Failed to initialize root");
>   receive_from = ANY;
> 
>   unlock_pm();
>   thread_cleanup(fp);
>   unlock_proc(fp);
>   return(NULL);
318c671
<  *				setreply				     *
---
>  *				lock_proc				     *
320,322c673
< void setreply(proc_nr, result)
< int proc_nr;			/* process to reply to */
< int result;			/* result of call (usually OK or error #) */
---
> void lock_proc(struct fproc *rfp, int force_lock)
324,328c675,677
< /* Fill in a reply message to be sent later to a user process.  System calls
<  * may occasionally fill in other fields, this is only for the main return
<  * value, and for setting the "must send reply" flag.
<  */
<   register struct mproc *rmp = &mproc[proc_nr];
---
>   int r;
>   struct fproc *org_fp;
>   struct worker_thread *org_self;
330,331c679
<   if(proc_nr < 0 || proc_nr >= NR_PROCS)
<       panic("setreply arg out of range: %d", proc_nr);
---
>   r = mutex_trylock(&rfp->fp_lock);
333,334c681,696
<   rmp->mp_reply.reply_res = result;
<   rmp->mp_flags |= REPLY;	/* reply pending */
---
>   /* Were we supposed to obtain this lock immediately? */
>   if (force_lock) {
> 	assert(r == 0);
> 	return;
>   }
> 
>   if (r == 0) return;
> 
>   org_fp = fp;
>   org_self = self;
> 
>   if ((r = mutex_lock(&rfp->fp_lock)) != 0)
> 	panic("unable to lock fproc lock: %d", r);
> 
>   fp = org_fp;
>   self = org_self;
338c700
<  *				sendreply				     *
---
>  *				unlock_proc				     *
340c702
< static void sendreply()
---
> void unlock_proc(struct fproc *rfp)
342,344c704
<   int proc_nr;
<   int s;
<   struct mproc *rmp;
---
>   int r;
346,364c706,707
<   /* Send out all pending reply messages, including the answer to
<    * the call just made above.
<    */
<   for (proc_nr=0, rmp=mproc; proc_nr < NR_PROCS; proc_nr++, rmp++) {
<       /* In the meantime, the process may have been killed by a
<        * signal (e.g. if a lethal pending signal was unblocked)
<        * without the PM realizing it. If the slot is no longer in
<        * use or the process is exiting, don't try to reply.
<        */
<       if ((rmp->mp_flags & (REPLY | IN_USE | EXITING)) ==
<           (REPLY | IN_USE)) {
<           s=sendnb(rmp->mp_endpoint, &rmp->mp_reply);
<           if (s != OK) {
<               printf("PM can't reply to %d (%s): %d\n",
<                   rmp->mp_endpoint, rmp->mp_name, s);
<           }
<           rmp->mp_flags &= ~REPLY;
<       }
<   }
---
>   if ((r = mutex_unlock(&rfp->fp_lock)) != 0)
> 	panic("Failed to unlock: %d", r);
368c711
<  *				get_nice_value				     *
---
>  *				thread_cleanup				     *
370,371c713
< static int get_nice_value(queue)
< int queue;				/* store mem chunks here */
---
> void thread_cleanup(struct fproc *rfp)
373,381c715,754
< /* Processes in the boot image have a priority assigned. The PM doesn't know
<  * about priorities, but uses 'nice' values instead. The priority is between 
<  * MIN_USER_Q and MAX_USER_Q. We have to scale between PRIO_MIN and PRIO_MAX.
<  */ 
<   int nice_val = (queue - USER_Q) * (PRIO_MAX-PRIO_MIN+1) / 
<       (MIN_USER_Q-MAX_USER_Q+1);
<   if (nice_val > PRIO_MAX) nice_val = PRIO_MAX;	/* shouldn't happen */
<   if (nice_val < PRIO_MIN) nice_val = PRIO_MIN;	/* shouldn't happen */
<   return nice_val;
---
> /* Clean up worker thread. Skip parts if this thread is not associated
>  * with a particular process (i.e., rfp is NULL) */
> 
> #if LOCK_DEBUG
>   if (rfp != NULL) {
> 	check_filp_locks_by_me();
> 	check_vnode_locks_by_me(rfp);
> 	check_vmnt_locks_by_me(rfp);
>   }
> #endif
> 
>   if (rfp != NULL && rfp->fp_flags & FP_PM_PENDING) {	/* Postponed PM call */
> 	job_m_in = rfp->fp_job.j_m_in;
> 	rfp->fp_flags &= ~FP_PM_PENDING;
> 	service_pm_postponed();
>   }
> 
> #if LOCK_DEBUG
>   if (rfp != NULL) {
> 	check_filp_locks_by_me();
> 	check_vnode_locks_by_me(rfp);
> 	check_vmnt_locks_by_me(rfp);
>   }
> #endif
> 
>   if (rfp != NULL) {
> 	rfp->fp_flags &= ~FP_DROP_WORK;
> 	if (rfp->fp_flags & FP_SRV_PROC) {
> 		struct vmnt *vmp;
> 
> 		if ((vmp = find_vmnt(rfp->fp_endpoint)) != NULL) {
> 			vmp->m_flags &= ~VMNT_CALLBACK;
> 		}
> 	}
>   }
> 
>   if (deadlock_resolving) {
> 	if (self->w_tid == dl_worker.w_tid)
> 		deadlock_resolving = 0;
>   }
385c758
<  *				handle_vfs_reply       			     *
---
>  *				get_work				     *
387c760
< static void handle_vfs_reply()
---
> static void get_work()
389,394c762,763
<   struct mproc *rmp;
<   endpoint_t proc_e;
<   int r, proc_n;
< 
<   /* PM_REBOOT is the only request not associated with a process.
<    * Handle its reply first.
---
>   /* Normally wait for new input.  However, if 'reviving' is
>    * nonzero, a suspended process must be awakened.
396,399c765,797
<   if (call_nr == PM_REBOOT_REPLY) {
< 	/* Ask the kernel to abort. All system services, including
< 	 * the PM, will get a HARD_STOP notification. Await the
< 	 * notification in the main loop.
---
>   int r, found_one, proc_p;
>   register struct fproc *rp;
> 
>   while (reviving != 0) {
> 	found_one = FALSE;
> 
> 	/* Find a suspended process. */
> 	for (rp = &fproc[0]; rp < &fproc[NR_PROCS]; rp++)
> 		if (rp->fp_pid != PID_FREE && (rp->fp_flags & FP_REVIVED)) {
> 			found_one = TRUE; /* Found a suspended process */
> 			if (unblock(rp))
> 				return;	/* So main loop can process job */
> 			send_work();
> 		}
> 
> 	if (!found_one)	/* Consistency error */
> 		panic("VFS: get_work couldn't revive anyone");
>   }
> 
>   for(;;) {
> 	/* Normal case.  No one to revive. Get a useful request. */
> 	if ((r = sef_receive(receive_from, &m_in)) != OK) {
> 		panic("VFS: sef_receive error: %d", r);
> 	}
> 
> 	proc_p = _ENDPOINT_P(m_in.m_source);
> 	if (proc_p < 0 || proc_p >= NR_PROCS) fp = NULL;
> 	else fp = &fproc[proc_p];
> 
> 	if (m_in.m_type == EDEADSRCDST) return;	/* Failed 'sendrec' */
> 
> 	/* Negative who_p is never used to access the fproc array. Negative
> 	 * numbers (kernel tasks) are treated in a special way.
401c799,805
< 	sys_abort(abort_flag);
---
> 	if (who_p >= (int)(sizeof(fproc) / sizeof(struct fproc)))
> 		panic("receive process out of range: %d", who_p);
> 	if (who_p >= 0 && fproc[who_p].fp_endpoint == NONE) {
> 		printf("VFS: ignoring request from %d: NONE endpoint %d (%d)\n",
> 			m_in.m_source, who_p, m_in.m_type);
> 		continue;
> 	}
402a807,819
> 	/* Internal consistency check; our mental image of process numbers and
> 	 * endpoints must match with how the rest of the system thinks of them.
> 	 */
> 	if (who_p >= 0 && fproc[who_p].fp_endpoint != who_e) {
> 		if (fproc[who_p].fp_endpoint == NONE)
> 			printf("slot unknown even\n");
> 
> 		printf("VFS: receive endpoint inconsistent (source %d, who_p "
> 			"%d, stored ep %d, who_e %d).\n", m_in.m_source, who_p,
> 			fproc[who_p].fp_endpoint, who_e);
> 		panic("VFS: inconsistent endpoint ");
> 	}
> 
404a822
> }
406,407c824,830
<   /* Get the process associated with this call */
<   proc_e = m_in.PM_PROC;
---
> /*===========================================================================*
>  *				reply					     *
>  *===========================================================================*/
> void reply(endpoint_t whom, int result)
> {
> /* Send a reply to a user process.  If the send fails, just ignore it. */
>   int r;
409,410c832,837
<   if (pm_isokendpt(proc_e, &proc_n) != OK) {
< 	panic("handle_vfs_reply: got bad endpoint from VFS: %d", proc_e);
---
>   m_out.reply_type = result;
>   r = sendnb(whom, &m_out);
>   if (r != OK) {
> 	printf("VFS: %d couldn't send reply %d to %d: %d\n", mthread_self(),
> 		result, whom, r);
> 	util_stacktrace();
411a839
> }
413c841,847
<   rmp = &mproc[proc_n];
---
> /*===========================================================================*
>  *				service_pm_postponed			     *
>  *===========================================================================*/
> static void service_pm_postponed(void)
> {
>   int r;
>   vir_bytes pc, newsp;
415,417c849,854
<   /* Now that VFS replied, mark the process as VFS-idle again */
<   if (!(rmp->mp_flags & VFS_CALL))
< 	panic("handle_vfs_reply: reply without request: %d", call_nr);
---
>   switch(job_call_nr) {
>     case PM_EXEC:
> 	{
> 		endpoint_t proc_e;
> 		vir_bytes exec_path, stack_frame;
> 		size_t exec_path_len, stack_frame_len;
419c856,860
<   rmp->mp_flags &= ~VFS_CALL;
---
> 		proc_e = job_m_in.PM_PROC;
> 		exec_path = (vir_bytes) job_m_in.PM_PATH;
> 		exec_path_len = (size_t) job_m_in.PM_PATH_LEN;
> 		stack_frame = (vir_bytes) job_m_in.PM_FRAME;
> 		stack_frame_len = (size_t) job_m_in.PM_FRAME_LEN;
421,422c862,863
<   if (rmp->mp_flags & UNPAUSED)
<   	panic("handle_vfs_reply: UNPAUSED set on entry: %d", call_nr);
---
> 		r = pm_exec(proc_e, exec_path, exec_path_len, stack_frame,
> 			    stack_frame_len, &pc, &newsp, job_m_in.PM_EXECFLAGS);
424,431c865,871
<   /* Call-specific handler code */
<   switch (call_nr) {
<   case PM_SETUID_REPLY:
<   case PM_SETGID_REPLY:
<   case PM_SETGROUPS_REPLY:
< 	/* Wake up the original caller */
< 	setreply(rmp-mproc, OK);
< 
---
> 		/* Reply status to PM */
> 		m_out.m_type = PM_EXEC_REPLY;
> 		m_out.PM_PROC = proc_e;
> 		m_out.PM_PC = (void*) pc;
> 		m_out.PM_STATUS = r;
> 		m_out.PM_NEWSP = (void *) newsp;
> 	}
434,436c874,877
<   case PM_SETSID_REPLY:
< 	/* Wake up the original caller */
< 	setreply(rmp-mproc, rmp->mp_procgrp);
---
>     case PM_EXIT:
> 	{
> 		endpoint_t proc_e;
> 		proc_e = job_m_in.PM_PROC;
437a879,884
> 		pm_exit(proc_e);
> 
> 		/* Reply dummy status to PM for synchronization */
> 		m_out.m_type = PM_EXIT_REPLY;
> 		m_out.PM_PROC = proc_e;
> 	}
440,442c887,891
<   case PM_EXEC_REPLY:
< 	exec_restart(rmp, m_in.PM_STATUS, (vir_bytes)m_in.PM_PC,
< 		(vir_bytes)m_in.PM_NEWSP);
---
>     case PM_DUMPCORE:
> 	{
> 		endpoint_t proc_e, traced_proc_e;
> 		int term_signal;
> 		vir_bytes core_path;
443a893,911
> 		proc_e = job_m_in.PM_PROC;
> 		traced_proc_e = job_m_in.PM_TRACED_PROC;
> 		if(job_m_in.PM_PROC != job_m_in.PM_TRACED_PROC) {
> 			/* dumpcore request */
> 			term_signal = 0;
> 		} else {
> 			/* dumpcore on exit */
> 			term_signal = job_m_in.PM_TERM_SIG;
> 		}
> 		core_path = (vir_bytes) job_m_in.PM_PATH;
> 
> 		r = pm_dumpcore(proc_e, term_signal, core_path);
> 
> 		/* Reply status to PM */
> 		m_out.m_type = PM_CORE_REPLY;
> 		m_out.PM_PROC = proc_e;
> 		m_out.PM_TRACED_PROC = traced_proc_e;
> 		m_out.PM_STATUS = r;
> 	}
446,447c914,916
<   case PM_EXIT_REPLY:
< 	exit_restart(rmp, FALSE /*dump_core*/);
---
>     default:
> 	panic("Unhandled postponed PM call %d", job_m_in.m_type);
>   }
448a918,944
>   r = send(PM_PROC_NR, &m_out);
>   if (r != OK)
> 	panic("service_pm_postponed: send failed: %d", r);
> }
> 
> /*===========================================================================*
>  *				service_pm				     *
>  *===========================================================================*/
> static void service_pm()
> {
>   int r, slot;
> 
>   switch (job_call_nr) {
>     case PM_SETUID:
> 	{
> 		endpoint_t proc_e;
> 		uid_t euid, ruid;
> 
> 		proc_e = job_m_in.PM_PROC;
> 		euid = job_m_in.PM_EID;
> 		ruid = job_m_in.PM_RID;
> 
> 		pm_setuid(proc_e, euid, ruid);
> 
> 		m_out.m_type = PM_SETUID_REPLY;
> 		m_out.PM_PROC = proc_e;
> 	}
451,453c947,950
<   case PM_CORE_REPLY:
< 	if (m_in.PM_STATUS == OK)
< 		rmp->mp_sigstatus |= DUMPED;
---
>     case PM_SETGID:
> 	{
> 		endpoint_t proc_e;
> 		gid_t egid, rgid;
455,463c952,954
< 	if (m_in.PM_PROC == m_in.PM_TRACED_PROC)
< 		/* The reply is to a core dump request
< 		 * for a killed process */
< 		exit_restart(rmp, TRUE /*dump_core*/);
< 	else
< 		/* The reply is to a core dump request
< 		 * for a traced process (T_DUMPCORE) */
< 		/* Wake up the original caller */
< 		setreply(rmp-mproc, rmp->mp_procgrp);
---
> 		proc_e = job_m_in.PM_PROC;
> 		egid = job_m_in.PM_EID;
> 		rgid = job_m_in.PM_RID;
464a956,960
> 		pm_setgid(proc_e, egid, rgid);
> 
> 		m_out.m_type = PM_SETGID_REPLY;
> 		m_out.PM_PROC = proc_e;
> 	}
467,471c963,971
<   case PM_FORK_REPLY:
< 	/* Schedule the newly created process ... */
< 	r = (OK);
< 	if (rmp->mp_scheduler != KERNEL && rmp->mp_scheduler != NONE) {
< 		r = sched_start_user(rmp->mp_scheduler, rmp);
---
>     case PM_SETSID:
> 	{
> 		endpoint_t proc_e;
> 
> 		proc_e = job_m_in.PM_PROC;
> 		pm_setsid(proc_e);
> 
> 		m_out.m_type = PM_SETSID_REPLY;
> 		m_out.PM_PROC = proc_e;
472a973
> 	break;
474,479c975,979
< 	/* If scheduling the process failed, we want to tear down the process
< 	 * and fail the fork */
< 	if (r != (OK)) {
< 		/* Tear down the newly created process */
< 		rmp->mp_scheduler = NONE; /* don't try to stop scheduling */
< 		exit_proc(rmp, -1, FALSE /*dump_core*/);
---
>     case PM_EXEC:
>     case PM_EXIT:
>     case PM_DUMPCORE:
> 	{
> 		endpoint_t proc_e = job_m_in.PM_PROC;
481,482c981,984
< 		/* Wake up the parent with a failed fork */
< 		setreply(rmp->mp_parent, -1);
---
> 		if(isokendpt(proc_e, &slot) != OK) {
> 			printf("VFS: proc ep %d not ok\n", proc_e);
> 			return;
> 		}
483a986,1012
> 		fp = &fproc[slot];
> 
> 		if (fp->fp_flags & FP_PENDING) {
> 			/* This process has a request pending, but PM wants it
> 			 * gone. Forget about the pending request and satisfy
> 			 * PM's request instead. Note that a pending request
> 			 * AND an EXEC request are mutually exclusive. Also, PM
> 			 * should send only one request/process at a time.
> 			 */
> 			 assert(fp->fp_job.j_m_in.m_source != PM_PROC_NR);
> 		}
> 
> 		/* PM requests on behalf of a proc are handled after the
> 		 * system call that might be in progress for that proc has
> 		 * finished. If the proc is not busy, we start a dummy call.
> 		 */
> 		if (!(fp->fp_flags & FP_PENDING) &&
> 					mutex_trylock(&fp->fp_lock) == 0) {
> 			mutex_unlock(&fp->fp_lock);
> 			worker_start(do_dummy);
> 			fp->fp_flags |= FP_DROP_WORK;
> 		}
> 
> 		fp->fp_job.j_m_in = job_m_in;
> 		fp->fp_flags |= FP_PM_PENDING;
> 
> 		return;
485,487c1014,1020
< 	else {
< 		/* Wake up the child */
< 		setreply(proc_n, OK);
---
>     case PM_FORK:
>     case PM_SRV_FORK:
> 	{
> 		endpoint_t pproc_e, proc_e;
> 		pid_t child_pid;
> 		uid_t reuid;
> 		gid_t regid;
489,490c1022,1037
< 		/* Wake up the parent */
< 		setreply(rmp->mp_parent, rmp->mp_pid);
---
> 		pproc_e = job_m_in.PM_PPROC;
> 		proc_e = job_m_in.PM_PROC;
> 		child_pid = job_m_in.PM_CPID;
> 		reuid = job_m_in.PM_REUID;
> 		regid = job_m_in.PM_REGID;
> 
> 		pm_fork(pproc_e, proc_e, child_pid);
> 		m_out.m_type = PM_FORK_REPLY;
> 
> 		if (job_call_nr == PM_SRV_FORK) {
> 			m_out.m_type = PM_SRV_FORK_REPLY;
> 			pm_setuid(proc_e, reuid, reuid);
> 			pm_setgid(proc_e, regid, regid);
> 		}
> 
> 		m_out.PM_PROC = proc_e;
491a1039,1044
> 	break;
>     case PM_SETGROUPS:
> 	{
> 		endpoint_t proc_e;
> 		int group_no;
> 		gid_t *group_addr;
492a1046,1054
> 		proc_e = job_m_in.PM_PROC;
> 		group_no = job_m_in.PM_GROUP_NO;
> 		group_addr = (gid_t *) job_m_in.PM_GROUP_ADDR;
> 
> 		pm_setgroups(proc_e, group_no, group_addr);
> 
> 		m_out.m_type = PM_SETGROUPS_REPLY;
> 		m_out.PM_PROC = proc_e;
> 	}
495,496c1057,1059
<   case PM_SRV_FORK_REPLY:
< 	/* Nothing to do */
---
>     case PM_UNPAUSE:
> 	{
> 		endpoint_t proc_e;
497a1061,1067
> 		proc_e = job_m_in.PM_PROC;
> 
> 		unpause(proc_e);
> 
> 		m_out.m_type = PM_UNPAUSE_REPLY;
> 		m_out.PM_PROC = proc_e;
> 	}
500,502c1070,1071
<   case PM_UNPAUSE_REPLY:
< 	/* Process is now unpaused */
< 	rmp->mp_flags |= UNPAUSED;
---
>     case PM_REBOOT:
> 	pm_reboot();
503a1073,1075
> 	/* Reply dummy status to PM for synchronization */
> 	m_out.m_type = PM_REBOOT_REPLY;
> 
506,507c1078,1081
<   default:
< 	panic("handle_vfs_reply: unknown reply code: %d", call_nr);
---
>     default:
> 	printf("VFS: don't know how to handle PM request %d\n", job_call_nr);
> 
> 	return;
510,512c1084,1125
<   /* Now that the process is idle again, look at pending signals */
<   if ((rmp->mp_flags & (IN_USE | EXITING)) == IN_USE)
< 	  restart_sigs(rmp);
---
>   r = send(PM_PROC_NR, &m_out);
>   if (r != OK)
> 	panic("service_pm: send failed: %d", r);
> 
> }
> 
> 
> /*===========================================================================*
>  *				unblock					     *
>  *===========================================================================*/
> static int unblock(rfp)
> struct fproc *rfp;
> {
>   int blocked_on;
> 
>   fp = rfp;
>   blocked_on = rfp->fp_blocked_on;
>   m_in.m_source = rfp->fp_endpoint;
>   m_in.m_type = rfp->fp_block_callnr;
>   m_in.fd = scratch(fp).file.fd_nr;
>   m_in.buffer = scratch(fp).io.io_buffer;
>   m_in.nbytes = scratch(fp).io.io_nbytes;
> 
>   rfp->fp_blocked_on = FP_BLOCKED_ON_NONE;	/* no longer blocked */
>   rfp->fp_flags &= ~FP_REVIVED;
>   reviving--;
>   assert(reviving >= 0);
> 
>   /* This should be a pipe I/O, not a device I/O. If it is, it'll 'leak'
>    * grants.
>    */
>   assert(!GRANT_VALID(rfp->fp_grant));
> 
>   /* Pending pipe reads/writes can be handled directly */
>   if (blocked_on == FP_BLOCKED_ON_PIPE) {
> 	worker_start(do_pending_pipe);
> 	yield();	/* Give thread a chance to run */
> 	self = NULL;
> 	return(0);	/* Retrieve more work */
>   }
> 
>   return(1);	/* We've unblocked a process */
